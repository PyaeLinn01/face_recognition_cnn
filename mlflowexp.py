"""
MLflow Tracking for Face Recognition Models (FaceNet & MTCNN)

This module provides experiment tracking for:
- FaceNet model: Face embedding generation and verification
- MTCNN: Face detection

Run this script to log model experiments to MLflow:
    python mlflowexp.py

View results:
    mlflow ui --port 5000

Then open http://localhost:5000 in your browser.
"""

import mlflow
import mlflow.keras
import mlflow.tensorflow
import numpy as np
import cv2
import os
import time
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# TensorFlow imports
import tensorflow as tf
from tensorflow.keras import backend as K

# Local imports
from fr_utils import load_weights_from_FaceNet, load_dataset, img_to_encoding
from inception_blocks_v2 import faceRecoModel

# Set MLflow tracking URI (local directory)
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "file:./mlruns")
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# Constants
TARGET_SIZE = (96, 96)
EMBEDDING_SIZE = 128


def get_model_summary_stats(model) -> Dict:
    """Extract model architecture statistics."""
    total_params = model.count_params()
    trainable_params = sum([K.count_params(w) for w in model.trainable_weights])
    non_trainable_params = total_params - trainable_params
    
    # Count layers by type
    layer_counts = {}
    for layer in model.layers:
        layer_type = layer.__class__.__name__
        layer_counts[layer_type] = layer_counts.get(layer_type, 0) + 1
    
    return {
        "total_params": total_params,
        "trainable_params": trainable_params,
        "non_trainable_params": non_trainable_params,
        "total_layers": len(model.layers),
        "layer_types": layer_counts
    }


def triplet_loss(y_true, y_pred, alpha=0.2):
    """
    Triplet loss function for face verification.
    
    Arguments:
        y_true: Not used, but required by Keras
        y_pred: List containing anchor, positive, and negative embeddings
        alpha: Margin for triplet loss (default 0.2)
    
    Returns:
        Loss value
    """
    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
    
    # Compute distance between anchor and positive
    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)
    
    # Compute distance between anchor and negative
    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)
    
    # Compute triplet loss
    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)
    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))
    
    return loss


def compute_embedding_quality_metrics(model, test_images: List[str]) -> Dict:
    """
    Compute quality metrics for embeddings generated by the model.
    
    Metrics include:
    - Mean embedding norm
    - Embedding variance
    - Inference time
    """
    embeddings = []
    inference_times = []
    
    for img_path in test_images:
        if not os.path.exists(img_path):
            continue
            
        start_time = time.time()
        try:
            embedding = img_to_encoding(img_path, model)
            inference_times.append(time.time() - start_time)
            embeddings.append(embedding.flatten())
        except Exception as e:
            print(f"Error processing {img_path}: {e}")
            continue
    
    if not embeddings:
        return {}
    
    embeddings = np.array(embeddings)
    
    metrics = {
        "mean_embedding_norm": float(np.mean(np.linalg.norm(embeddings, axis=1))),
        "std_embedding_norm": float(np.std(np.linalg.norm(embeddings, axis=1))),
        "mean_inference_time_ms": float(np.mean(inference_times) * 1000),
        "min_inference_time_ms": float(np.min(inference_times) * 1000),
        "max_inference_time_ms": float(np.max(inference_times) * 1000),
        "embedding_dimension": EMBEDDING_SIZE,
        "num_test_images": len(embeddings)
    }
    
    return metrics


def compute_verification_metrics(
    model, 
    database: Dict[str, np.ndarray], 
    test_pairs: List[Tuple[str, str, bool]],
    threshold: float = 0.5
) -> Dict:
    """
    Compute verification metrics (accuracy, precision, recall, F1).
    
    Args:
        model: FaceNet model
        database: Dictionary of name -> embedding
        test_pairs: List of (image_path, identity, is_same_person)
        threshold: Distance threshold for verification
    
    Returns:
        Dictionary of metrics
    """
    true_positives = 0
    true_negatives = 0
    false_positives = 0
    false_negatives = 0
    distances = []
    
    for img_path, identity, is_same in test_pairs:
        if not os.path.exists(img_path) or identity not in database:
            continue
            
        try:
            encoding = img_to_encoding(img_path, model)
            dist = float(np.linalg.norm(encoding - database[identity]))
            distances.append(dist)
            
            predicted_same = dist < threshold
            
            if is_same and predicted_same:
                true_positives += 1
            elif is_same and not predicted_same:
                false_negatives += 1
            elif not is_same and predicted_same:
                false_positives += 1
            else:
                true_negatives += 1
        except Exception as e:
            print(f"Error in verification: {e}")
            continue
    
    total = true_positives + true_negatives + false_positives + false_negatives
    
    if total == 0:
        return {}
    
    accuracy = (true_positives + true_negatives) / total
    precision = true_positives / max(1, true_positives + false_positives)
    recall = true_positives / max(1, true_positives + false_negatives)
    f1 = 2 * precision * recall / max(1e-8, precision + recall)
    
    return {
        "verification_accuracy": float(accuracy),
        "verification_precision": float(precision),
        "verification_recall": float(recall),
        "verification_f1": float(f1),
        "true_positives": true_positives,
        "true_negatives": true_negatives,
        "false_positives": false_positives,
        "false_negatives": false_negatives,
        "mean_distance": float(np.mean(distances)) if distances else 0.0,
        "std_distance": float(np.std(distances)) if distances else 0.0,
        "threshold_used": threshold
    }


def compute_intra_inter_class_distances(database: Dict[str, np.ndarray]) -> Dict:
    """
    Compute intra-class and inter-class distance statistics.
    
    This helps evaluate embedding quality:
    - Low intra-class distance: Same person's embeddings are close
    - High inter-class distance: Different people's embeddings are far apart
    """
    names = list(database.keys())
    embeddings = [database[name].flatten() for name in names]
    
    if len(embeddings) < 2:
        return {}
    
    # Compute pairwise distances
    inter_distances = []
    for i in range(len(embeddings)):
        for j in range(i + 1, len(embeddings)):
            dist = np.linalg.norm(embeddings[i] - embeddings[j])
            inter_distances.append(dist)
    
    return {
        "mean_inter_class_distance": float(np.mean(inter_distances)),
        "std_inter_class_distance": float(np.std(inter_distances)),
        "min_inter_class_distance": float(np.min(inter_distances)),
        "max_inter_class_distance": float(np.max(inter_distances)),
        "num_identities": len(names)
    }


def log_facenet_experiment(run_name: str = None):
    """
    Log FaceNet model experiment to MLflow.
    
    This logs:
    - Model parameters (architecture, input shape, embedding size)
    - Training configuration
    - Performance metrics
    - Model artifacts
    """
    print("=" * 60)
    print("FaceNet MLflow Experiment")
    print("=" * 60)
    
    # Set experiment
    experiment_name = "FaceNet_Face_Recognition"
    mlflow.set_experiment(experiment_name)
    
    if run_name is None:
        run_name = f"facenet_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        print(f"Starting MLflow run: {run_name}")
        
        # ============ Load Model ============
        print("\n[1/5] Loading FaceNet model...")
        K.set_image_data_format("channels_last")
        model = faceRecoModel(input_shape=(96, 96, 3))
        load_weights_from_FaceNet(model)
        model.compile(optimizer='adam', loss=triplet_loss, metrics=['accuracy'])
        print(f"Total Parameters: {model.count_params():,}")
        
        # ============ Log Parameters ============
        print("\n[2/5] Logging model parameters...")
        
        # Model architecture parameters
        mlflow.log_param("model_name", "FaceNet")
        mlflow.log_param("model_type", "Inception-based CNN")
        mlflow.log_param("input_shape", "(96, 96, 3)")
        mlflow.log_param("embedding_size", EMBEDDING_SIZE)
        mlflow.log_param("optimizer", "adam")
        mlflow.log_param("loss_function", "triplet_loss")
        mlflow.log_param("triplet_margin_alpha", 0.2)
        mlflow.log_param("verification_threshold", 0.5)
        mlflow.log_param("channels_format", "channels_last")
        
        # Get model summary stats
        model_stats = get_model_summary_stats(model)
        mlflow.log_param("total_params", model_stats["total_params"])
        mlflow.log_param("trainable_params", model_stats["trainable_params"])
        mlflow.log_param("non_trainable_params", model_stats["non_trainable_params"])
        mlflow.log_param("total_layers", model_stats["total_layers"])
        
        # Log layer type counts
        for layer_type, count in model_stats["layer_types"].items():
            mlflow.log_param(f"layer_count_{layer_type}", count)
        
        # ============ Build Database ============
        print("\n[3/5] Building face database from images...")
        
        database = {}
        images_dir = Path("images")
        test_images = []
        
        # Scan for registered users (directories with images)
        if images_dir.exists():
            for user_dir in images_dir.iterdir():
                if user_dir.is_dir():
                    user_name = user_dir.name
                    user_images = list(user_dir.glob("*.jpg")) + list(user_dir.glob("*.png"))
                    
                    if user_images:
                        # Use first image for database
                        first_img = str(user_images[0])
                        try:
                            database[user_name] = img_to_encoding(first_img, model)
                            print(f"  Registered: {user_name} ({len(user_images)} images)")
                            test_images.extend([str(img) for img in user_images])
                        except Exception as e:
                            print(f"  Error registering {user_name}: {e}")
            
            # Also check for loose images in images/ folder
            for img_file in images_dir.glob("*.jpg"):
                name = img_file.stem
                if name not in database:
                    try:
                        database[name] = img_to_encoding(str(img_file), model)
                        test_images.append(str(img_file))
                        print(f"  Registered: {name}")
                    except Exception as e:
                        print(f"  Error: {e}")
        
        mlflow.log_param("registered_identities", len(database))
        mlflow.log_param("total_test_images", len(test_images))
        
        # ============ Compute Metrics ============
        print("\n[4/5] Computing performance metrics...")
        
        # Embedding quality metrics
        if test_images:
            embedding_metrics = compute_embedding_quality_metrics(model, test_images[:20])
            for key, value in embedding_metrics.items():
                mlflow.log_metric(key, value)
                print(f"  {key}: {value:.4f}")
        
        # Inter-class distance metrics
        if len(database) >= 2:
            distance_metrics = compute_intra_inter_class_distances(database)
            for key, value in distance_metrics.items():
                if isinstance(value, (int, float)):
                    mlflow.log_metric(key, value)
                    print(f"  {key}: {value:.4f}")
        
        # Create synthetic test pairs for verification
        test_pairs = []
        db_names = list(database.keys())
        for name in db_names[:5]:  # Test first 5 identities
            for img_path in test_images[:10]:
                if name in img_path:
                    test_pairs.append((img_path, name, True))
                elif db_names:
                    # Use a different identity for negative pair
                    other_name = [n for n in db_names if n != name and n not in img_path]
                    if other_name:
                        test_pairs.append((img_path, other_name[0], False))
        
        if test_pairs and database:
            verification_metrics = compute_verification_metrics(
                model, database, test_pairs, threshold=0.5
            )
            for key, value in verification_metrics.items():
                if isinstance(value, (int, float)):
                    mlflow.log_metric(key, value)
                    print(f"  {key}: {value:.4f}" if isinstance(value, float) else f"  {key}: {value}")
        
        # ============ Log Artifacts ============
        print("\n[5/5] Logging model artifacts...")
        
        # Save model summary to file
        summary_file = "model_summary.txt"
        with open(summary_file, "w") as f:
            f.write("FaceNet Model Summary\n")
            f.write("=" * 50 + "\n\n")
            model.summary(print_fn=lambda x: f.write(x + "\n"))
            f.write(f"\n\nDatabase Identities: {list(database.keys())}\n")
        mlflow.log_artifact(summary_file)
        os.remove(summary_file)
        
        # Save database info
        db_info_file = "database_info.json"
        db_info = {
            "identities": list(database.keys()),
            "count": len(database),
            "embedding_size": EMBEDDING_SIZE,
            "timestamp": datetime.now().isoformat()
        }
        with open(db_info_file, "w") as f:
            json.dump(db_info, f, indent=2)
        mlflow.log_artifact(db_info_file)
        os.remove(db_info_file)
        
        # Log the model (optional - can be large)
        # mlflow.keras.log_model(model, "facenet_model")
        
        print("\n" + "=" * 60)
        print("FaceNet experiment logged successfully!")
        print(f"Run ID: {mlflow.active_run().info.run_id}")
        print("=" * 60)
        
        return mlflow.active_run().info.run_id


def log_mtcnn_experiment(run_name: str = None):
    """
    Log MTCNN face detection experiment to MLflow.
    
    This logs:
    - Detection parameters
    - Performance metrics (speed, accuracy)
    - Detection statistics
    """
    print("\n" + "=" * 60)
    print("MTCNN MLflow Experiment")
    print("=" * 60)
    
    # Import MTCNN
    try:
        from mtcnn.mtcnn import MTCNN
    except ImportError:
        print("MTCNN not available. Install with: pip install mtcnn")
        return None
    
    # Set experiment
    experiment_name = "MTCNN_Face_Detection"
    mlflow.set_experiment(experiment_name)
    
    if run_name is None:
        run_name = f"mtcnn_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        print(f"Starting MLflow run: {run_name}")
        
        # ============ Initialize Detector ============
        print("\n[1/4] Initializing MTCNN detector...")
        
        # MTCNN parameters (use defaults, log them for reference)
        min_face_size = 20
        scale_factor = 0.709
        confidence_thresholds = [0.6, 0.7, 0.7]  # P-Net, R-Net, O-Net
        
        # Initialize MTCNN with default settings (API varies by version)
        detector = MTCNN()
        print("MTCNN detector initialized")
        
        # ============ Log Parameters ============
        print("\n[2/4] Logging MTCNN parameters...")
        
        mlflow.log_param("model_name", "MTCNN")
        mlflow.log_param("model_type", "Multi-task Cascaded CNN")
        mlflow.log_param("stages", "P-Net, R-Net, O-Net")
        mlflow.log_param("min_face_size", min_face_size)
        mlflow.log_param("scale_factor", scale_factor)
        mlflow.log_param("pnet_threshold", confidence_thresholds[0])
        mlflow.log_param("rnet_threshold", confidence_thresholds[1])
        mlflow.log_param("onet_threshold", confidence_thresholds[2])
        mlflow.log_param("output_type", "bounding_box + keypoints")
        mlflow.log_param("keypoints", "left_eye, right_eye, nose, mouth_left, mouth_right")
        
        # ============ Run Detection Tests ============
        print("\n[3/4] Running face detection tests...")
        
        images_dir = Path("images")
        detection_results = []
        inference_times = []
        total_faces_detected = 0
        
        if images_dir.exists():
            # Get all test images
            test_images = list(images_dir.glob("**/*.jpg")) + list(images_dir.glob("**/*.png"))
            
            for img_path in test_images[:30]:  # Test up to 30 images
                try:
                    img = cv2.imread(str(img_path))
                    if img is None:
                        continue
                    
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    
                    start_time = time.time()
                    faces = detector.detect_faces(img_rgb)
                    inference_time = time.time() - start_time
                    
                    inference_times.append(inference_time)
                    total_faces_detected += len(faces)
                    
                    # Get confidence scores
                    confidences = [f.get("confidence", 0) for f in faces]
                    
                    detection_results.append({
                        "image": str(img_path),
                        "faces_detected": len(faces),
                        "inference_time_ms": inference_time * 1000,
                        "confidences": confidences,
                        "image_size": img.shape[:2]
                    })
                    
                    print(f"  {img_path.name}: {len(faces)} faces, {inference_time*1000:.1f}ms")
                    
                except Exception as e:
                    print(f"  Error processing {img_path}: {e}")
                    continue
        
        # ============ Log Metrics ============
        print("\n[4/4] Logging detection metrics...")
        
        if inference_times:
            mlflow.log_metric("mean_inference_time_ms", float(np.mean(inference_times) * 1000))
            mlflow.log_metric("min_inference_time_ms", float(np.min(inference_times) * 1000))
            mlflow.log_metric("max_inference_time_ms", float(np.max(inference_times) * 1000))
            mlflow.log_metric("std_inference_time_ms", float(np.std(inference_times) * 1000))
            
            print(f"  Mean inference time: {np.mean(inference_times)*1000:.2f}ms")
            print(f"  Min inference time: {np.min(inference_times)*1000:.2f}ms")
            print(f"  Max inference time: {np.max(inference_times)*1000:.2f}ms")
        
        if detection_results:
            faces_per_image = [r["faces_detected"] for r in detection_results]
            all_confidences = [c for r in detection_results for c in r["confidences"]]
            
            mlflow.log_metric("total_images_processed", len(detection_results))
            mlflow.log_metric("total_faces_detected", total_faces_detected)
            mlflow.log_metric("mean_faces_per_image", float(np.mean(faces_per_image)))
            mlflow.log_metric("detection_rate", float(sum(1 for f in faces_per_image if f > 0) / len(faces_per_image)))
            
            if all_confidences:
                mlflow.log_metric("mean_confidence", float(np.mean(all_confidences)))
                mlflow.log_metric("min_confidence", float(np.min(all_confidences)))
                mlflow.log_metric("max_confidence", float(np.max(all_confidences)))
            
            print(f"  Total images: {len(detection_results)}")
            print(f"  Total faces: {total_faces_detected}")
            print(f"  Detection rate: {sum(1 for f in faces_per_image if f > 0) / len(faces_per_image):.2%}")
        
        # Save detection results
        results_file = "detection_results.json"
        with open(results_file, "w") as f:
            json.dump(detection_results, f, indent=2, default=str)
        mlflow.log_artifact(results_file)
        os.remove(results_file)
        
        print("\n" + "=" * 60)
        print("MTCNN experiment logged successfully!")
        print(f"Run ID: {mlflow.active_run().info.run_id}")
        print("=" * 60)
        
        return mlflow.active_run().info.run_id


def log_combined_pipeline_experiment(run_name: str = None):
    """
    Log combined MTCNN + FaceNet pipeline experiment.
    
    This tests the full face recognition pipeline:
    1. Face detection (MTCNN)
    2. Face alignment and preprocessing
    3. Embedding generation (FaceNet)
    4. Face verification
    """
    print("\n" + "=" * 60)
    print("Combined Pipeline MLflow Experiment")
    print("=" * 60)
    
    try:
        from mtcnn.mtcnn import MTCNN
    except ImportError:
        print("MTCNN not available")
        return None
    
    experiment_name = "Face_Recognition_Pipeline"
    mlflow.set_experiment(experiment_name)
    
    if run_name is None:
        run_name = f"pipeline_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        print(f"Starting MLflow run: {run_name}")
        
        # Initialize models
        print("\n[1/3] Loading models...")
        K.set_image_data_format("channels_last")
        facenet_model = faceRecoModel(input_shape=(96, 96, 3))
        load_weights_from_FaceNet(facenet_model)
        mtcnn_detector = MTCNN()
        print("Models loaded successfully")
        
        # Log pipeline parameters
        print("\n[2/3] Logging pipeline parameters...")
        mlflow.log_param("pipeline_name", "MTCNN + FaceNet")
        mlflow.log_param("detection_model", "MTCNN")
        mlflow.log_param("embedding_model", "FaceNet")
        mlflow.log_param("input_size_facenet", "(96, 96, 3)")
        mlflow.log_param("embedding_dim", 128)
        mlflow.log_param("verification_threshold", 0.5)
        mlflow.log_param("min_detection_confidence", 0.9)
        
        # Test pipeline on images
        print("\n[3/3] Testing full pipeline...")
        images_dir = Path("images")
        pipeline_times = []
        successful_recognitions = 0
        total_tests = 0
        
        if images_dir.exists():
            test_images = list(images_dir.glob("**/*.jpg"))[:20]
            
            for img_path in test_images:
                try:
                    start_time = time.time()
                    
                    # Step 1: Load and detect
                    img = cv2.imread(str(img_path))
                    if img is None:
                        continue
                    
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    faces = mtcnn_detector.detect_faces(img_rgb)
                    
                    if not faces:
                        continue
                    
                    # Step 2: Get best face
                    best_face = max(faces, key=lambda x: x.get("confidence", 0))
                    x, y, w, h = best_face["box"]
                    
                    # Step 3: Crop and resize
                    face_crop = img_rgb[max(0,y):y+h, max(0,x):x+w]
                    if face_crop.size == 0:
                        continue
                    
                    face_resized = cv2.resize(face_crop, TARGET_SIZE)
                    face_normalized = face_resized / 255.0
                    
                    # Step 4: Get embedding
                    embedding = facenet_model.predict(np.expand_dims(face_normalized, axis=0))
                    
                    pipeline_time = time.time() - start_time
                    pipeline_times.append(pipeline_time)
                    total_tests += 1
                    
                    if embedding is not None and embedding.shape[-1] == 128:
                        successful_recognitions += 1
                    
                    print(f"  {img_path.name}: Pipeline time {pipeline_time*1000:.1f}ms")
                    
                except Exception as e:
                    print(f"  Error: {e}")
                    continue
        
        # Log pipeline metrics
        if pipeline_times:
            mlflow.log_metric("mean_pipeline_time_ms", float(np.mean(pipeline_times) * 1000))
            mlflow.log_metric("min_pipeline_time_ms", float(np.min(pipeline_times) * 1000))
            mlflow.log_metric("max_pipeline_time_ms", float(np.max(pipeline_times) * 1000))
            mlflow.log_metric("pipeline_success_rate", float(successful_recognitions / max(1, total_tests)))
            mlflow.log_metric("total_tests", total_tests)
            mlflow.log_metric("successful_recognitions", successful_recognitions)
            
            print(f"\n  Mean pipeline time: {np.mean(pipeline_times)*1000:.2f}ms")
            print(f"  Success rate: {successful_recognitions}/{total_tests}")
        
        print("\n" + "=" * 60)
        print("Pipeline experiment logged successfully!")
        print(f"Run ID: {mlflow.active_run().info.run_id}")
        print("=" * 60)
        
        return mlflow.active_run().info.run_id


def run_all_experiments():
    """Run all MLflow experiments."""
    print("\n" + "=" * 70)
    print("        RUNNING ALL MLFLOW EXPERIMENTS")
    print("=" * 70)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Run FaceNet experiment
    facenet_run_id = log_facenet_experiment(f"facenet_{timestamp}")
    
    # Run MTCNN experiment
    mtcnn_run_id = log_mtcnn_experiment(f"mtcnn_{timestamp}")
    
    # Run combined pipeline experiment
    pipeline_run_id = log_combined_pipeline_experiment(f"pipeline_{timestamp}")
    
    print("\n" + "=" * 70)
    print("        ALL EXPERIMENTS COMPLETED")
    print("=" * 70)
    print("\nRun IDs:")
    print(f"  FaceNet:  {facenet_run_id}")
    print(f"  MTCNN:    {mtcnn_run_id}")
    print(f"  Pipeline: {pipeline_run_id}")
    print("\nTo view results, run:")
    print("  mlflow ui --port 5000")
    print("\nThen open http://localhost:5000 in your browser")
    print("=" * 70)
    
    return {
        "facenet": facenet_run_id,
        "mtcnn": mtcnn_run_id,
        "pipeline": pipeline_run_id
    }


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="MLflow tracking for Face Recognition models")
    parser.add_argument(
        "--experiment", 
        choices=["facenet", "mtcnn", "pipeline", "all"],
        default="all",
        help="Which experiment to run (default: all)"
    )
    parser.add_argument(
        "--run-name",
        type=str,
        default=None,
        help="Custom run name"
    )
    
    args = parser.parse_args()
    
    if args.experiment == "facenet":
        log_facenet_experiment(args.run_name)
    elif args.experiment == "mtcnn":
        log_mtcnn_experiment(args.run_name)
    elif args.experiment == "pipeline":
        log_combined_pipeline_experiment(args.run_name)
    else:
        run_all_experiments()